# ğŸŒŠ Hydropower Forecasting with Machine Learning
IBM SkillsBuild Hydropower Climate Optimisation Challenge (Zindi Africa): https://zindi.africa/competitions/ibm-skillsbuild-hydropower-climate-optimisation-challenge

This project was developed as part of the IBM SkillsBuild Hydropower Climate Optimisation Challenge
, which aims to improve hydropower generation forecasts for off-grid communities using climate data and machine learning.

This repository contains data preprocessing, exploratory analysis, modeling, and an interactive Streamlit application for results visualization.

---

## ğŸ“‚ Repository Structure
<details>
  <summary>Structure Visualization</summary>
    
  ```
project-name/
â”œâ”€â”€ README.md                   <- Project overview and usage
â”œâ”€â”€ requirements.txt            <- Main Python dependencies
â”œâ”€â”€ .gitignore                  <- Ignored files for git
â”œâ”€â”€ data/                       <- (optional placeholder for local datasets)
â”‚   â””â”€â”€ maybe_leave_out/        <- Not tracked / excluded from repo
â”‚
â”œâ”€â”€ notebooks/                  <- Explanatory notebooks (EDA & baseline only)
â”‚   â”œâ”€â”€ 0_preprocessing.ipynb
â”‚   â”œâ”€â”€ 1_exploration.ipynb
â”‚   â”œâ”€â”€ 2_time_series_decomp.ipynb
â”‚   â””â”€â”€ 3_naive_baseline_model.ipynb
â”‚
â”œâ”€â”€ src/ 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/                   <- include here only the data sets
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data.csv
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ Prophet.py
â”‚   â”‚   â”œâ”€â”€ ANN.py
â”‚   â”‚   â””â”€â”€ LightGBM.py
â”‚   â””â”€â”€ utils/                  <- can be removed if it has not content (see other comments)
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data.py             <- load_data + preprocess, could include here or in data/
â”‚       â”œâ”€â”€ plots.py            <- here or in visualization/
â”‚       â””â”€â”€ train_utils.py      <- include if data/ or visualization/ depend on it train_utils.py
â”‚
â”œâ”€â”€ app/                        <- Interactive Streamlit application
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â”œâ”€â”€ requirements.txt        <- App-specific dependencies
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data.csv
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ page1.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”‚   â””â”€â”€ visualization.py
â”‚   â””â”€â”€ images/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ logo.png
â”‚
â””â”€â”€ reports/                    <- Generated outputs and presentation
      â”œâ”€â”€ figures/
      â”‚   â””â”€â”€ figure1.png
      â””â”€â”€ Presentation.pptx
  ```
</details>

### Data
- Place raw datasets into `data/` (not tracked in GitHub).  
- Processed data is generated using `src/data/preprocess.py`.  

### Notebooks (storytelling only)
- **0_preprocessing.ipynb** â†’ demonstrates data cleaning steps.  
- **1_exploration.ipynb** â†’ exploratory analysis and visualization.  
- **2_time_series_decomp.ipynb** â†’ seasonal/trend decomposition.  
- **3_naive_baseline_model.ipynb** â†’ simple baseline for benchmarking.  

### Models
- Located in `src/models/`  
  - `Prophet.ipynb` â€“ Prophet model implementation  
  - `ANN.ipynb` â€“ Neural network model  
  - `LightGBM.ipynb` â€“ Gradient boosting model  
  - `train_utils.py` â€“ shared functions for training/evaluation  

### Visualizations
- Custom plots in `src/visualization/plots.py`.  
- Figures stored in `reports/figures/`.

### Streamlit app

### Reports

---

## âš™ï¸ Setup

### 1. Clone the repository
```bash
git clone https://github.com/your-username/project-name.git
cd project-name
```

### 2. Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ“Š Workflow

### Data
- Place raw datasets into `data/` (not tracked in GitHub).  
- Processed data is generated using `src/data/preprocess.py`.  

### Notebooks (storytelling only)
- **0_preprocessing.ipynb** â†’ demonstrates data cleaning steps.  
- **1_exploration.ipynb** â†’ exploratory analysis and visualization.  
- **2_time_series_decomp.ipynb** â†’ seasonal/trend decomposition.  
- **3_naive_baseline_model.ipynb** â†’ simple baseline for benchmarking.  

### Models
- Located in `src/models/`  
  - `Prophet.ipynb` â€“ Prophet model implementation  
  - `ANN.ipynb` â€“ Neural network model  
  - `LightGBM.ipynb` â€“ Gradient boosting model  
  - `train_utils.py` â€“ shared functions for training/evaluation  

### Visualizations
- Custom plots in `src/visualization/plots.py`.  
- Figures stored in `reports/figures/`.  

---

## ğŸš€ Running the Streamlit App

Navigate to the `app/` directory and install its dependencies:

```bash
cd app
pip install -r requirements.txt
```

Run the app:

```bash
streamlit run streamlit_app.py
```

This launches an interactive dashboard with multiple pages, powered by data in `app/data/`.

---

## ğŸ“‘ Reports

- **Figures** â†’ `reports/figures/`  
- **Presentation slides** â†’ `reports/Presentation.pptx`  

---

## ğŸ“Œ Notes

- `src/` contains the authoritative code for reproducibility.  
- `notebooks/` are explanatory and showcase data preparation, EDA, and baseline results.  
- Use `configs/config.yaml` for project settings (paths, parameters).  
- Raw data should **not** be committed to GitHub.  

---

## âœ¨ Authors

This project was developed collaboratively by the entire project team.  
**All members contributed equally to every stage of the project, including data preparation, modeling, visualization, app development, and reporting.**

- [Your Name]  
- [Collaborator 1]  
- [Collaborator 2]
