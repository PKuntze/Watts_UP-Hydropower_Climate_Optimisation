{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47137e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "import zipfile\n",
    "import gc\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import pandas as pd\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import Naive\n",
    "from sklearn.metrics import mean_absolute_error # Optional, for evaluation if needed\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb81ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load and Prepare Data ---\n",
    "# Load daily aggregated data\n",
    "df = pd.read_csv('/Users/noeespinosa/Documents/10-Data-analysis/00-capstone-project/Watts_UP-Hydropower_Climate_Optimisation/data/daily_merged_hydro_climate.csv')\n",
    "\n",
    "# Ensure 'date' is datetime type\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Train/Test Split ---\n",
    "# Define the cutoff based on: \n",
    "    # df_train = df.loc[df.date_time <= pd.to_datetime('2024-08-23 23:00:00'),:]\n",
    "    # df_test = df.loc[df.date_time > pd.to_datetime('2024-08-23 23:00:00'),:]\n",
    "# Note: Since data is daily, time '23:00:00' is likely not present. \n",
    "# Filtering on date <= '2024-08-23' is the standard approach for daily data.\n",
    "# I'll filter based on the 'date' column.\n",
    "train_cutoff_date = pd.to_datetime('2024-08-23') # Using just the date part\n",
    "\n",
    "# Filter based on the 'date' column\n",
    "df_train = df.loc[df['date'] <= train_cutoff_date, :].copy()\n",
    "df_test = df.loc[df['date'] > train_cutoff_date, :].copy()\n",
    "\n",
    "print(\"--- Data Split ---\")\n",
    "print(f\"Training data date range: {df_train['date'].min().date()} to {df_train['date'].max().date()}\")\n",
    "print(f\"Testing data date range: {df_test['date'].min().date()} to {df_test['date'].max().date()}\")\n",
    "print(f\"Training set size (user-days): {len(df_train)}\")\n",
    "print(f\"Testing set size (user-days): {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb292621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Prepare Data for StatsForecast ---\n",
    "# Rename columns to match statsforecast expectations: unique_id, ds, y\n",
    "# Using 'Source' for user ID, 'date' for datetime, and 'kwh_sum' for the target daily consumption\n",
    "sf_train = df_train.rename(columns={\n",
    "    'Source': 'unique_id',\n",
    "    'date': 'ds',        # Renaming 'date' to 'ds'\n",
    "    'kwh_sum': 'y'       # Renaming 'kwh_sum' to 'y'\n",
    "})[['unique_id', 'ds', 'y']] # Select only needed columns\n",
    "\n",
    "# Ensure 'ds' is datetime (it should be after the rename if it was datetime before)\n",
    "sf_train['ds'] = pd.to_datetime(sf_train['ds'])\n",
    "\n",
    "# Sort by user and date (good practice in time series analysis)\n",
    "sf_train = sf_train.sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n--- Prepared Training Data (Sample) ---\")\n",
    "print(sf_train.head())\n",
    "print(f\"Shape: {sf_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b532ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Fit the Naive Model ---\n",
    "print(\"\\n--- Fitting Naive Model ---\")\n",
    "# Define the Naive model\n",
    "models = [Naive()]\n",
    "\n",
    "# Initialize StatsForecast\n",
    "# freq='D' indicates daily data\n",
    "sf = StatsForecast(\n",
    "    models=models,\n",
    "    freq='D',\n",
    "    n_jobs=-1 # Use all cores/ CPUs available in the machine to make it faster\n",
    ")\n",
    "\n",
    "# Fit the model on the prepared training data\n",
    "# This will fit a separate Naive model for each unique_id (user)\n",
    "sf.fit(sf_train)\n",
    "print(\"Naive model fitted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Define Forecast Horizon (Based on Test Set Dates) ---\n",
    "# Get the unique dates in the test set to forecast\n",
    "test_dates = sorted(df_test['date'].unique()) # Use 'date' column from original df_test\n",
    "print(f\"\\n--- Forecast Horizon ---\")\n",
    "print(f\"Forecasting for dates: {test_dates[0].date()} to {test_dates[-1].date()}\")\n",
    "print(f\"Number of days to forecast: {len(test_dates)}\")\n",
    "\n",
    "# Create the future dataframe for statsforecast\n",
    "# This specifies for which user-date combinations we want forecasts\n",
    "# We forecast for users seen in training, for the dates in the test set\n",
    "unique_users_in_train = sf_train['unique_id'].unique()\n",
    "future_df = pd.DataFrame([\n",
    "    (uid, date)\n",
    "    for uid in unique_users_in_train\n",
    "    for date in test_dates\n",
    "], columns=['unique_id', 'ds'])\n",
    "\n",
    "# Ensure 'ds' in future_df is also datetime\n",
    "future_df['ds'] = pd.to_datetime(future_df['ds'])\n",
    "\n",
    "print(f\"Future dataframe created for {len(future_df)} user-date combinations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7fa3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Generate Forecasts ---\n",
    "print(\"\\n--- Generating Forecasts ---\")\n",
    "# Generate forecasts for the specified horizon and user-date combinations\n",
    "# h=len(test_dates) means forecast 'len(test_dates)' steps ahead for each series\n",
    "forecasts = sf.predict(h=len(test_dates), level=[])\n",
    "print(\"Forecasts generated.\")\n",
    "print(forecasts.head(10)) # Show sample forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a18fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Prepare Test Data for Evaluation ---\n",
    "# Rename test data columns for clarity and merging\n",
    "df_test_renamed = df_test.rename(columns={\n",
    "    'Source': 'unique_id',\n",
    "    'date': 'ds',         # Rename 'date' to 'ds' to match forecasts\n",
    "    'kwh_sum': 'actual_y' # Rename target for clarity\n",
    "})[['unique_id', 'ds', 'actual_y']] # Select relevant columns\n",
    "df_test_renamed['ds'] = pd.to_datetime(df_test_renamed['ds']) # Ensure datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ddee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Merge Forecasts with Actuals for Evaluation ---\n",
    "print(\"\\n--- Evaluating Model ---\")\n",
    "# Merge forecasts (which have 'Naive' column) with actuals from test set\n",
    "# Merge on both 'unique_id' and 'ds' (date)\n",
    "evaluation_df = pd.merge(\n",
    "    df_test_renamed,\n",
    "    forecasts[['unique_id', 'ds', 'Naive']], # Select forecast columns\n",
    "    on=['unique_id', 'ds'],\n",
    "    how='inner' # Inner join ensures we only evaluate where we have both forecast and actual\n",
    ")\n",
    "\n",
    "# Rename forecast column for clarity\n",
    "evaluation_df.rename(columns={'Naive': 'predicted_y'}, inplace=True)\n",
    "\n",
    "print(f\"Evaluation DataFrame shape (matching user-date pairs): {evaluation_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2784de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. Calculate Evaluation Metrics ---\n",
    "if not evaluation_df.empty:\n",
    "    y_true = evaluation_df['actual_y']\n",
    "    y_pred = evaluation_df['predicted_y']\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    print(f\"\\n--- Evaluation Metrics for Daily Naive Model ---\")\n",
    "    print(f\"Number of evaluated user-day predictions: {len(evaluation_df)}\")\n",
    "    print(f\"MAE: {mae:.6f} kWh\")\n",
    "    print(f\"RMSE: {rmse:.6f} kWh\")\n",
    "\n",
    "    # Optional: Display a sample of the comparison\n",
    "    print(\"\\nSample of Actual vs Forecasted Daily Totals:\")\n",
    "    print(evaluation_df.head(10))\n",
    "else:\n",
    "    print(\"Warning: Evaluation DataFrame is empty. Check user/date alignment between train/test/forecast.\")\n",
    "\n",
    "print(\"\\n--- Process Complete ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac6c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# --- ASSUMPTION: I have run the previous evaluation code and have these variables:\n",
    "# df_train, df_test_renamed, forecasts, evaluation_df\n",
    "# sf_train (prepared training data for statsforecast)\n",
    "\n",
    "# --- 1. Select a User to Plot ---\n",
    "# I will pick one from df_train['Source'].unique() or df_test['Source'].unique()\n",
    "user_to_plot = 'consumer_device_10_data_user_4' # <--- CHANGE THIS TO THE USER ID TO BE PLOTTED\n",
    "\n",
    "print(f\"--- Plotting for User: {user_to_plot} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369dbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Prepare Data for the Selected User ---\n",
    "# a. Training Data for the user (from the correctly formatted sf_train)\n",
    "train_user = sf_train[sf_train['unique_id'] == user_to_plot].copy()\n",
    "# b. Test Data (Actuals) for the user (from df_test_renamed which uses 'ds')\n",
    "test_user = df_test_renamed[df_test_renamed['unique_id'] == user_to_plot].copy()\n",
    "# c. Forecasts for the user\n",
    "forecast_user = forecasts[forecasts['unique_id'] == user_to_plot].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e858e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Diagnostic Checks ---\n",
    "print(f\"Train data points for {user_to_plot}: {len(train_user)}\")\n",
    "if not train_user.empty:\n",
    "    print(f\"  Train date range: {train_user['ds'].min().date()} to {train_user['ds'].max().date()}\")\n",
    "\n",
    "print(f\"Test data points for {user_to_plot}: {len(test_user)}\")\n",
    "if not test_user.empty:\n",
    "    print(f\"  Test date range: {test_user['ds'].min().date()} to {test_user['ds'].max().date()}\")\n",
    "\n",
    "print(f\"Forecast data points for {user_to_plot}: {len(forecast_user)}\")\n",
    "if not forecast_user.empty:\n",
    "    print(f\"  Forecast date range: {forecast_user['ds'].min().date()} to {forecast_user['ds'].max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9780f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Check if data exists for the selected user and proceed ---\n",
    "# We need forecasts and test data to make a meaningful comparison plot\n",
    "if forecast_user.empty or test_user.empty:\n",
    "    print(f\"Warning: Missing forecasts or test data for user {user_to_plot}. Cannot generate plot.\")\n",
    "else:\n",
    "    # Sort by date for correct line plotting (essential)\n",
    "    train_user = train_user.sort_values('ds')\n",
    "    test_user = test_user.sort_values('ds')\n",
    "    forecast_user = forecast_user.sort_values('ds')\n",
    "    # --- 5. Create the Plot ---\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Plot Training Data (if available)\n",
    "    if not train_user.empty:\n",
    "        plt.plot(train_user['ds'], train_user['y'], label='Train Data', color='blue', marker='o', linestyle='-', linewidth=1, markersize=4)\n",
    "        print(\"Plotted Train Data.\")\n",
    "\n",
    "    # Plot Test Data (Actuals) - This is the actual historical data for the test period\n",
    "    plt.plot(test_user['ds'], test_user['actual_y'], label='Actual Test Data', color='green', marker='s', linestyle='-', linewidth=2, markersize=4)\n",
    "    print(\"Plotted Actual Test Data.\")\n",
    "\n",
    "    # Plot Forecasts - These are the model's predictions for the test period\n",
    "    plt.plot(forecast_user['ds'], forecast_user['Naive'], label='Naive Forecast', color='red', marker='^', linestyle='--', linewidth=2, markersize=4)\n",
    "    print(\"Plotted Naive Forecast.\")\n",
    "\n",
    "    # --- 6. Formatting ---\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Daily Energy Consumption (kWh)')\n",
    "    plt.title(f'Daily Energy Consumption: Train, Test, and Naive Forecast for {user_to_plot}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    # --- Crucial: Set x-axis limits to include all relevant periods ---\n",
    "    # Find the overall min and max dates to display across all available series\n",
    "    all_series_to_plot = [test_user['ds'], forecast_user['ds']] # Always include test and forecast\n",
    "    if not train_user.empty:\n",
    "        all_series_to_plot.append(train_user['ds']) # Include train if it exists\n",
    "\n",
    "    all_dates = pd.concat(all_series_to_plot).dropna()\n",
    "    if not all_dates.empty:\n",
    "        x_min = all_dates.min()\n",
    "        x_max = all_dates.max()\n",
    "        # Add a small buffer for better visualization\n",
    "        buffer_days = max(2, int((x_max - x_min).days * 0.05)) # 5% buffer or at least 2 days\n",
    "        plt.xlim(left=x_min - pd.Timedelta(days=buffer_days), right=x_max + pd.Timedelta(days=buffer_days))\n",
    "        print(f\"Set x-axis limits from ~{x_min.date()} to ~{x_max.date()}\")\n",
    "    else:\n",
    "        print(\"Warning: Could not determine date range for x-axis.\")\n",
    "\n",
    "    # Improve date formatting on the x-axis for better readability\n",
    "    plt.gca().xaxis.set_major_locator(plt.MaxNLocator(10)) # Adjust number of ticks if needed\n",
    "    plt.xticks(rotation=45, ha='right') # Rotate labels\n",
    "\n",
    "    # --- 7. Display the Plot ---\n",
    "    plt.tight_layout() # Adjust layout to prevent clipping of labels\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Plot generated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
