{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a32bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e974b8f",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c79e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load the climate data\n",
    "\n",
    "file_path = \"Kalam Climate Data.xlsx\"   \n",
    "climate_df = pd.read_excel(file_path)\n",
    "\n",
    "climate_df['Date Time'] = pd.to_datetime(climate_df['Date Time'])\n",
    "\n",
    "# Extract date\n",
    "\n",
    "climate_df['date'] = climate_df['Date Time'].dt.date\n",
    "\n",
    "# Daily aggregation\n",
    "daily_climate = climate_df.groupby('date').agg({\n",
    "    'Temperature (°C)': ['mean', 'min', 'max'],\n",
    "    'Dewpoint Temperature (°C)': ['mean', 'min', 'max'],\n",
    "    'U Wind Component (m/s)': 'mean',\n",
    "    'V Wind Component (m/s)': 'mean',\n",
    "    'Total Precipitation (mm)': 'sum',\n",
    "    'Snowfall (mm)': 'sum',\n",
    "    'Snow Cover (%)': 'mean'\n",
    "})\n",
    "\n",
    "# Flatten columns\n",
    "daily_climate.columns = ['_'.join(col).strip() for col in daily_climate.columns.values]\n",
    "\n",
    "# Reset index\n",
    "daily_climate = daily_climate.reset_index()\n",
    "\n",
    "# Define start and end dates\n",
    "start_date = pd.to_datetime('2024-09-24')\n",
    "end_date   = pd.to_datetime('2024-10-24')\n",
    "\n",
    "daily_climate[\"date\"] = pd.to_datetime(daily_climate[\"date\"])\n",
    "\n",
    "# Filter DataFrame\n",
    "extra_month_df = daily_climate[(daily_climate['date'] >= start_date) & (daily_climate['date'] <= end_date)]\n",
    "\n",
    "\n",
    "new_names = {\n",
    "    'date': 'Date',\n",
    "    'Temperature (°C)_mean': 'Temp_Mean',\n",
    "    'Temperature (°C)_min': 'Temp_Min',\n",
    "    'Temperature (°C)_max': 'Temp_Max',\n",
    "    'Dewpoint Temperature (°C)_mean': 'Dewpoint_Mean',\n",
    "    'Dewpoint Temperature (°C)_min': 'Dewpoint_Min',\n",
    "    'Dewpoint Temperature (°C)_max': 'Dewpoint_Max',\n",
    "    'U Wind Component (m/s)_mean': 'U_Wind_Mean',\n",
    "    'V Wind Component (m/s)_mean': 'V_Wind_Mean',\n",
    "    'Total Precipitation (mm)_sum': 'Precipitation_Sum',\n",
    "    'Snowfall (mm)_sum': 'Snowfall_Sum',\n",
    "    'Snow Cover (%)_mean': 'SnowCover_Mean'\n",
    "}\n",
    "\n",
    "\n",
    "extra_month_df.rename(columns=new_names, inplace=True)\n",
    "\n",
    "all_data_df = pd.read_csv(\"Data.csv\")\n",
    "\n",
    "all_data_df.drop(columns=[\"consumer_device_9\", \"consumer_device_x\", \"v_red\", \"v_blue\",\"v_yellow\", \"current\", \"power_factor\"], inplace=True)\n",
    "all_data_df.head()\n",
    "\n",
    "# Ensure datetime\n",
    "all_data_df['date_time'] = pd.to_datetime(all_data_df['date_time'])\n",
    "\n",
    "\n",
    "# Extract date (drop time)\n",
    "all_data_df['date'] = all_data_df['date_time'].dt.date\n",
    "\n",
    "\n",
    "# Group by Source (consumer_device + data_user) and date\n",
    "\n",
    "daily_df = all_data_df.groupby(['Source', 'date']).agg({\n",
    "    'kwh': 'sum'  \n",
    "})\n",
    "\n",
    "daily_df = daily_df.reset_index()\n",
    "\n",
    "\n",
    "# Ensure datetime index\n",
    "daily_df = daily_df.set_index(\"date\").sort_index()\n",
    "daily_climate = daily_climate.set_index(\"date\").sort_index()\n",
    "\n",
    "# Merge\n",
    "merged_daily_df = daily_df.join(daily_climate, how=\"left\")\n",
    "\n",
    "\n",
    "merged_daily_df.reset_index(inplace=True)\n",
    "\n",
    "merged_daily_df.to_csv(\"second_daily_merged_hydro_climate.csv\", index=False)\n",
    "\n",
    "\n",
    "# Dictionary mapping old names to new names\n",
    "new_names = {\n",
    "    'date': 'Date',\n",
    "    'Source': 'Source',\n",
    "    'kwh': 'kwh',\n",
    "    'Temperature (°C)_mean': 'Temp_Mean',\n",
    "    'Temperature (°C)_min': 'Temp_Min',\n",
    "    'Temperature (°C)_max': 'Temp_Max',\n",
    "    'Dewpoint Temperature (°C)_mean': 'Dewpoint_Mean',\n",
    "    'Dewpoint Temperature (°C)_min': 'Dewpoint_Min',\n",
    "    'Dewpoint Temperature (°C)_max': 'Dewpoint_Max',\n",
    "    'U Wind Component (m/s)_mean': 'U_Wind_Mean',\n",
    "    'V Wind Component (m/s)_mean': 'V_Wind_Mean',\n",
    "    'Total Precipitation (mm)_sum': 'Precipitation_Sum',\n",
    "    'Snowfall (mm)_sum': 'Snowfall_Sum',\n",
    "    'Snow Cover (%)_mean': 'SnowCover_Mean'\n",
    "}\n",
    "\n",
    "merged_daily_df.rename(columns=new_names, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14663002",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b67197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"Temp_dew_diff\"] = df[\"Temp_Mean\"] - df[\"Dewpoint_Mean\"]\n",
    "    df[\"wind_speed\"] = np.sqrt(df[\"U_Wind_Mean\"]**2 + df[\"V_Wind_Mean\"]**2)\n",
    "    df[\"precip_snow_ratio\"] = df[\"Precipitation_Sum\"] / (df[\"Snowfall_Sum\"] + 1e-6)\n",
    "    return df\n",
    "\n",
    "def add_lag_roll(df, group_col=\"Source\", target_col=\"kwh\", lags=[1,2,7], windows=[3,7]):\n",
    "    df = df.sort_values([\"Source\",\"Date\"]).copy()\n",
    "    for lag in lags:\n",
    "        df[f\"lag_{lag}\"] = df.groupby(group_col)[target_col].shift(lag)\n",
    "    for w in windows:\n",
    "        df[f\"roll_mean_{w}\"] = df.groupby(group_col)[target_col].shift(1).rolling(w).mean()\n",
    "    return df\n",
    "\n",
    "# --- Reindex all Sources across full date range ---\n",
    "\n",
    "def reindex_sources(df):\n",
    "    all_dates = pd.date_range(df[\"Date\"].min(), df[\"Date\"].max())\n",
    "    all_sources = df[\"Source\"].unique()\n",
    "    idx = pd.MultiIndex.from_product([all_sources, all_dates], names=[\"Source\",\"Date\"])\n",
    "    df_full = df.set_index([\"Source\",\"Date\"]).reindex(idx).reset_index()\n",
    "    # fill missing kwh with 0\n",
    "    df_full[\"kwh\"] = df_full[\"kwh\"].fillna(0)\n",
    "    # climate features same across sources, fill forward\n",
    "    climate_cols = [c for c in df.columns if c not in [\"Source\",\"kwh\",\"Date\"]]\n",
    "    for c in climate_cols:\n",
    "        df_full[c] = df_full.groupby(\"Date\")[c].transform(\"first\")\n",
    "    return df_full\n",
    "\n",
    "# --- Prepare dataset ---\n",
    "df = merged_daily_df.copy()\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = reindex_sources(df)\n",
    "df = add_features(df)\n",
    "df = add_lag_roll(df)\n",
    "\n",
    "# Drop rows without lag features\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "feature_cols = [\n",
    "    \"Temp_Mean\",\"Temp_Min\",\"Temp_Max\",\"Dewpoint_Mean\",\"Dewpoint_Min\",\"Dewpoint_Max\",\n",
    "    \"U_Wind_Mean\",\"V_Wind_Mean\",\"Precipitation_Sum\",\"Snowfall_Sum\",\"SnowCover_Mean\",\n",
    "    \"Temp_dew_diff\",\"wind_speed\",\"precip_snow_ratio\",\n",
    "] + [c for c in df.columns if c.startswith(\"lag_\") or c.startswith(\"roll_\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efe444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train/test split ---\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ced746",
   "metadata": {},
   "source": [
    "# Let us train a LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972e7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "reg = LGBMRegressor(n_estimators=300, random_state=42)\n",
    "reg.fit(train_df[feature_cols], train_df[\"kwh\"])\n",
    "test_df[\"pred_kwh\"] = np.maximum(0, reg.predict(test_df[feature_cols]))\n",
    "\n",
    "# --- Global Metrics ---\n",
    "print(\"=== Global Metrics ===\")\n",
    "rmse = mean_squared_error(test_df[\"kwh\"], test_df[\"pred_kwh\"], squared=False)\n",
    "mape = mean_absolute_percentage_error(test_df[\"kwh\"], test_df[\"pred_kwh\"])\n",
    "print(f\"Regression: RMSE={rmse:.3f} \\n\")\n",
    "\n",
    "# --- Per Source Metrics ---\n",
    "print(\"=== Per Source Metrics ===\")\n",
    "sources = df[\"Source\"].unique()\n",
    "per_source_results = []\n",
    "for src in sources:\n",
    "    t_src = test_df[test_df[\"Source\"]==src]\n",
    "    if len(t_src)==0:\n",
    "        continue\n",
    "    rmse = mean_squared_error(t_src[\"kwh\"], t_src[\"pred_kwh\"], squared=False)\n",
    "    mape = mean_absolute_percentage_error(t_src[\"kwh\"], t_src[\"pred_kwh\"])\n",
    "    per_source_results.append((src, rmse))\n",
    "\n",
    "per_source_df = pd.DataFrame(per_source_results, columns=[\"Source\",\"RMSE\"])\n",
    "print(per_source_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b91d41",
   "metadata": {},
   "source": [
    "# Prediction for the extra month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a2afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Predict next month (extra data) ---\n",
    "extra = add_features(extra_month_df.copy())\n",
    "extra[\"Date\"] = pd.to_datetime(extra[\"Date\"])\n",
    "preds = []\n",
    "for src in sources:\n",
    "    hist = df[df[\"Source\"]==src].copy()\n",
    "    extra_src = extra.copy()\n",
    "    extra_src[\"Source\"] = src\n",
    "    lag_hist = hist.tail(7).reset_index(drop=True)  # last 7 days\n",
    "    rows = []\n",
    "    for _, row in extra_src.iterrows():\n",
    "        r = row.to_dict()\n",
    "        # lag & rolling features\n",
    "        for lag in [1,2,7]:\n",
    "            if len(lag_hist) >= lag:\n",
    "                r[f\"lag_{lag}\"] = lag_hist.loc[len(lag_hist)-lag,\"kwh\"]\n",
    "            else:\n",
    "                r[f\"lag_{lag}\"] = np.nan\n",
    "        for w in [3,7]:\n",
    "            if len(lag_hist) >= w:\n",
    "                r[f\"roll_mean_{w}\"] = lag_hist[\"kwh\"].iloc[-w:].mean()\n",
    "            else:\n",
    "                r[f\"roll_mean_{w}\"] = lag_hist[\"kwh\"].mean()\n",
    "        # predict kwh directly\n",
    "        X = pd.DataFrame([r])[feature_cols].fillna(0)\n",
    "        r[\"pred_kwh\"] = max(0, reg.predict(X)[0])  # clip negatives\n",
    "        # update history\n",
    "        lag_hist = pd.concat([lag_hist, pd.DataFrame([{\"kwh\": r[\"pred_kwh\"]}])], ignore_index=True)\n",
    "        rows.append(r)\n",
    "    preds.append(pd.DataFrame(rows))\n",
    "preds_df = pd.concat(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811fc411",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ffa427",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_source(src):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    d = df[df[\"Source\"]==src]\n",
    "    plt.plot(d[\"Date\"], d[\"kwh\"], label=\"actual\")\n",
    "    d_extra = preds_df[preds_df[\"Source\"]==src]\n",
    "    plt.plot(d_extra[\"Date\"], d_extra[\"pred_kwh\"], \"--\", label=\"pred (extra month)\")\n",
    "    plt.title(f\"Source {src}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment to plot consumption for each of the sources:\n",
    "#for src in sources:\n",
    "#    plot_source(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20edc6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total consumption plot\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(df.groupby(\"Date\")[\"kwh\"].sum(), label=\"actual total\")\n",
    "plt.plot(preds_df.groupby(\"Date\")[\"pred_kwh\"].sum(), \"--\", label=\"pred total (extra month)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
